{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddda2ee4-1a4f-484f-9273-0ef82029b6b1",
   "metadata": {},
   "source": [
    "# Coding Assignment \"Bonus #2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83dda4e-6c84-4cca-8f70-a904ec31a7b0",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d804dc-959e-4bfe-92fa-05331944ec7d",
   "metadata": {},
   "source": [
    "### 1.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023745f-67c1-4ac7-ad0b-bbddd3a8e246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modules.\n",
    "import torch\n",
    "import colorsys\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import networkx as nx \n",
    "\n",
    "# Submodules\n",
    "import torch.nn as nn\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Methods\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dee7b0-2d44-41ff-8a52-9d94147db039",
   "metadata": {},
   "source": [
    "### 1.2. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98080586-20dd-481b-b4f5-5c4b710545ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The function generates returns the numpy array\n",
    "# of num_colors distinctive colors in RGB format.\n",
    "def generate_distinctive_colors(num_colors):\n",
    "    colors = []\n",
    "    hue_step = 1.0 / num_colors\n",
    "    saturation = 0.7\n",
    "    value = 0.9\n",
    "    for i in range(num_colors):\n",
    "        hue = i * hue_step\n",
    "        rgb = colorsys.hsv_to_rgb(hue, saturation, value)\n",
    "        colors.append(rgb)\n",
    "    return np.array(colors)\n",
    "\n",
    "# The function generates a scatter plot of nodes (=FMI stations) using \n",
    "# latitude and longitude as coordinates. \n",
    "def plotFMI(G_FMI):\n",
    "    # Get the number of clusters.\n",
    "    num_clusters = len(set([G_FMI.nodes[node]['cluster'] for node in G_FMI.nodes]))\n",
    "    \n",
    "    # Get the colors for clusters.\n",
    "    colors = generate_distinctive_colors(num_clusters)\n",
    "    \n",
    "    # Get the coordinates of the stations.\n",
    "    coords = np.array([G_FMI.nodes[node]['coord'] for node in G_FMI.nodes])\n",
    "    \n",
    "    # Draw nodes\n",
    "    for node in G_FMI.nodes:\n",
    "        color = colors[G_FMI.nodes[node]['cluster']]\n",
    "        plt.scatter(coords[node,1], coords[node,0], color=color, s=4, zorder=5)  # zorder ensures nodes are on top of edges\n",
    "        plt.text(coords[node,1]+0.1, coords[node,0]+0.2, str(node), fontsize=8, ha='center', va='center', color=color, fontweight='bold')\n",
    "    \n",
    "    # Draw edges\n",
    "    for edge in G_FMI.edges:\n",
    "        plt.plot([coords[edge[0],1],coords[edge[1],1]], [coords[edge[0],0],coords[edge[1],0]], linestyle='-', color='gray', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('longitude')\n",
    "    plt.ylabel('latitude')\n",
    "    plt.title('FMI stations')\n",
    "    plt.show()\n",
    "\n",
    "# The function below extracts a feature and label from each row \n",
    "# of dataframe df. Each row is expected to hold a FMI weather \n",
    "# measurement with cols \"Latitude\", \"Longitude\", \"temp\", \"Timestamp\". \n",
    "# Returns numpy arrays X, y.\n",
    "def ExtractFeatureMatrixLabelVector(data):\n",
    "    n_features = 7 \n",
    "    n_datapoints = len(data)\n",
    "    \n",
    "    # We build the feature matrix X (each of its rows hold the features of a data point) \n",
    "    # and the label vector y (whose entries hold the labels of data points).\n",
    "    X = np.zeros((n_datapoints, n_features))\n",
    "    y = np.zeros((n_datapoints, 1))\n",
    "\n",
    "    # Iterate over all rows in dataframe and create corresponding feature vector and label. \n",
    "    for i in range(n_datapoints):\n",
    "        # Latitude of FMI station, normalized by 100. \n",
    "        lat = float(data['Latitude'].iloc[i])/100\n",
    "        # Longitude of FMI station, normalized by 100.\n",
    "        lon = float(data['Longitude'].iloc[i])/100\n",
    "        # Temperature value of the data point.\n",
    "        tmp = data['temp'].iloc[i]\n",
    "        # Read the date and time of the temperature measurement. \n",
    "        date_object = datetime.strptime(data['Timestamp'].iloc[i], '%Y-%m-%d %H:%M:%S')\n",
    "        # Extract year, month, day, hour, and minute. Normalize these values \n",
    "        # to ensure that the features are in range [0,1].\n",
    "        year = float(date_object.year)/2025\n",
    "        month = float(date_object.month)/13\n",
    "        day = float(date_object.day)/32\n",
    "        hour = float(date_object.hour)/25\n",
    "        minute = float(date_object.minute)/61\n",
    "        \n",
    "        # Store the data point's features and a label.\n",
    "        X[i,:] = [lat, lon, year, month, day, hour, minute]\n",
    "        y[i,:] = tmp\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def add_edges(graph_FMI, num_neighbors):\n",
    "    # Copy the nodes to a new graph.\n",
    "    graph = graph_FMI.copy()\n",
    "    \n",
    "    for node in graph.nodes:\n",
    "        \n",
    "        # Representation vector of the node.\n",
    "        z_node = graph.nodes[node]['z']\n",
    "        \n",
    "        # Create storages for discrepancies and the corresponding neighbors.\n",
    "        d_mins = np.full(shape=num_neighbors, fill_value=1e10)\n",
    "        edges = np.full(shape=(num_neighbors, 2), fill_value=(node, -1))\n",
    "        \n",
    "        # Iterate over nodes to find the neighbors. \n",
    "        for potential_neighbor in graph.nodes:\n",
    "            if potential_neighbor != node:\n",
    "                # Representation vector of the potential neighbor.\n",
    "                z_neighbor = graph.nodes[potential_neighbor]['z']\n",
    "                d = LA.norm(z_node - z_neighbor)\n",
    "\n",
    "                # Find the max discrepancy so far.\n",
    "                d_max_idx = np.argmax(d_mins)\n",
    "                d_max = d_mins[d_max_idx]\n",
    "                \n",
    "                # Check if the new discrepancy is less than \n",
    "                # the current maximum one.\n",
    "                if d < d_max:\n",
    "                    d_mins[d_max_idx] = d\n",
    "                    edges[d_max_idx][1] = potential_neighbor\n",
    "\n",
    "        graph.add_edges_from(edges) \n",
    "\n",
    "    return graph\n",
    "\n",
    "def add_edges_gradient_loss(graph_FMI, num_neighbors, X, y):\n",
    "    # Copy the nodes to a new graph.\n",
    "    graph = graph_FMI.copy()\n",
    "    \n",
    "    # Define and fit the Linear regression.\n",
    "    linear_reg = LinearRegression()\n",
    "    linear_reg.fit(X, y)\n",
    "\n",
    "    # Extract the weight vector.\n",
    "    w_hat = linear_reg.coef_\n",
    "\n",
    "    # Calculate the average squared error loss.\n",
    "    for node in graph.nodes:\n",
    "        node_X = graph.nodes[node]['X']\n",
    "        node_y = graph.nodes[node]['y']\n",
    "        m = graph.nodes[node]['samplesize']\n",
    "        loss = (-2/m) * node_X.T.dot(node_y - node_X.dot(w_hat.T))\n",
    "        graph.nodes[node]['z'] = loss\n",
    "\n",
    "    # Add edges.\n",
    "    graph = add_edges(graph, num_neighbors)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290c0f0-3337-4b85-947a-a510e8be1861",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d57f38-979b-4966-9807-e49d2b0710b8",
   "metadata": {},
   "source": [
    "### 2.1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6157ceea-f9b5-4ba0-8198-08819593a03c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the weather measurements.\n",
    "data_FMI = pd.read_csv('Assignment_MLBasicsData.csv')\n",
    "\n",
    "# We consider each temperature measurement (=a row in dataframe) as a \n",
    "# separate data point.\n",
    "# Get the numbers of data points and the unique stations.\n",
    "n_stations = len(data_FMI.name.unique())\n",
    "n_datapoints = len(data_FMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e84074-b871-4e58-b6ca-0f0d54299f62",
   "metadata": {},
   "source": [
    "### 2.2. Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851769c-38aa-49d3-997b-d2f6a7438ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels from the FMI data.\n",
    "X_global, y_global = ExtractFeatureMatrixLabelVector(data_FMI)\n",
    "\n",
    "print(f\"The created feature matrix contains {np.shape(X_global)[0]} entries of {np.shape(X_global)[1]} features each.\")\n",
    "print(f\"The created label vector contains {np.shape(y_global)[0]} measurements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9ff43-a402-4e1d-832e-fba3bd5e3c56",
   "metadata": {},
   "source": [
    "### 2.3. Empirical graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e126e2-6556-403b-9ca5-6e1b6dd01fed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a networkX graph\n",
    "G_FMI = nx.Graph()\n",
    "\n",
    "# Add a one node per station\n",
    "G_FMI.add_nodes_from(range(0, n_stations))\n",
    "\n",
    "for i, station in enumerate(data_FMI.name.unique()):\n",
    "    # Extract data of a certain station\n",
    "    station_data = data_FMI[data_FMI.name==station]\n",
    "    \n",
    "    # Extract features and labels of a certain station.\n",
    "    X_node, y_node = ExtractFeatureMatrixLabelVector(station_data)\n",
    "    \n",
    "    # Split the dataset into training and validation set. \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_node, y_node, test_size=0.2, random_state=4740)\n",
    "    \n",
    "    # Store the station's data in the node's attributes. \n",
    "    G_FMI.nodes[i]['samplesize'] = len(y_node) # The number of measurements of the i-th weather station.\n",
    "    G_FMI.nodes[i]['name'] = station # The name of the i-th weather station.\n",
    "    G_FMI.nodes[i]['coord'] = np.array([station_data.Latitude.iloc[0], station_data.Longitude.iloc[0]]) # The coordinates of the i-th weather station.\n",
    "    G_FMI.nodes[i]['X'] = X_node # The feature matrix for local dataset at node i.\n",
    "    G_FMI.nodes[i]['y'] = y_node  # The  label vector for local dataset at node i.\n",
    "    G_FMI.nodes[i]['X_train'] = X_train # The training feature matrix for local dataset at node i\n",
    "    G_FMI.nodes[i]['y_train'] = y_train  # The training label vector for local dataset at node i\n",
    "    G_FMI.nodes[i]['X_val'] = X_val # The training feature matrix for local dataset at node i\n",
    "    G_FMI.nodes[i]['y_val'] = y_val  # The training label vector for local dataset at node i\n",
    "    G_FMI.nodes[i]['z'] = None # The representation vector for local dataset at node i.\n",
    "    G_FMI.nodes[i]['cluster'] = 0 # The cluster to which the node is assigned (default value = 0).\n",
    "    G_FMI.nodes[i]['model'] = None\n",
    "    G_FMI.nodes[i]['updated_params'] = None\n",
    "\n",
    "# Construct edges based on the similar gradient of the loss. \n",
    "G_FMI_with_edges = add_edges_gradient_loss(G_FMI, 4, X_global, y_global)\n",
    "\n",
    "# Visualize the empirical graph.\n",
    "print(f\"The graph is connected: {nx.is_connected(G_FMI_with_edges)}\")\n",
    "plotFMI(G_FMI_with_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66efb967-7539-4ee6-add4-20dbb16714e9",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec1868d-7bc5-415a-b224-7bfe3715babf",
   "metadata": {},
   "source": [
    "### 3.1. Student task - Neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ed673-dd40-491a-bf55-916d710086c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################TODO####################\n",
    "# TODO: Construct a neural network.\n",
    "#\n",
    "# NOTE: PyTorch tutorials: https://pytorch.org/tutorials/\n",
    "#\n",
    "# Grading: 11 points for the average validation error <= 25,\n",
    "#          5.5 points for the average validation error <= 30,\n",
    "#          0 points for the average validation error > 30 .\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbb2ea5-2ec6-4d6a-a35d-920365f109e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model in each node\n",
    "for node in G_FMI_with_edges.nodes:\n",
    "    G_FMI_with_edges.nodes[node]['model'] = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff147d-5818-4192-9276-b4042b28f268",
   "metadata": {},
   "source": [
    "### 3.2. FedGD with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681bd3d-609e-4bc4-95b5-f34b9524d27a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "alpha = 0.5\n",
    "l_rate = 0.01\n",
    "\n",
    "# Define initial values and storage\n",
    "prev_loss_avg = 1e10\n",
    "curr_loss_avg = 1e9\n",
    "tol = 0.01\n",
    "n_iterations = 0\n",
    "\n",
    "# Iterate while the average loss over all nodes is decreasing\n",
    "while curr_loss_avg < prev_loss_avg:\n",
    "    \n",
    "    n_iterations += 1\n",
    "    losses = np.zeros(n_stations)\n",
    "    \n",
    "    # Iterate over all nodes\n",
    "    for current_node in G_FMI_with_edges.nodes:\n",
    "        model = G_FMI_with_edges.nodes[current_node]['model']\n",
    "        \n",
    "        # Get training data.\n",
    "        X_train = torch.tensor(G_FMI_with_edges.nodes[current_node]['X_train'], dtype=torch.float32)\n",
    "        y_train = torch.tensor(G_FMI_with_edges.nodes[current_node]['y_train'], dtype=torch.float32)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_train)\n",
    "        loss = torch.nn.functional.mse_loss(outputs, y_train)\n",
    "        losses[current_node] = loss\n",
    "        \n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Gather parameters and send to neighbors\n",
    "        with torch.no_grad():\n",
    "            # Get the local parameters\n",
    "            local_params = [param.data for param in model.parameters()]\n",
    "            \n",
    "            # Get the gradient of the local loss.\n",
    "            term_1 = [param.grad for param in model.parameters()]\n",
    "            \n",
    "            term_2 = 0\n",
    "            neighbors = list(G_FMI_with_edges.neighbors(current_node))\n",
    "            for neighbor in neighbors:\n",
    "                neighbor_params = [param.data for param in G_FMI_with_edges.nodes[neighbor]['model'].parameters()]\n",
    "                \n",
    "                params_diff = [neighbor - local for neighbor, local in zip(neighbor_params, local_params)]\n",
    "                if term_2 == 0:\n",
    "                    term_2 = params_diff\n",
    "                else:\n",
    "                    term_2 = [a + b for a, b in zip(term_2, params_diff)]\n",
    "\n",
    "            term_2 = [a * 2 * alpha for a in term_2]\n",
    "            \n",
    "            # Equation 5.9\n",
    "            G_FMI_with_edges.nodes[current_node]['updated_params'] = [local - l_rate * (t_1 + t_2) for local, t_1, t_2 in zip(local_params, term_1, term_2)]\n",
    "\n",
    "    for node in G_FMI_with_edges.nodes:\n",
    "        model_node = G_FMI_with_edges.nodes[node]['model']\n",
    "        for i, param in enumerate(model_node.parameters()):\n",
    "            param.data = nn.parameter.Parameter(G_FMI_with_edges.nodes[node]['updated_params'][i])\n",
    "            param.grad = None\n",
    "    \n",
    "    prev_loss_avg = curr_loss_avg\n",
    "    curr_loss_avg = np.mean(losses)\n",
    "    print(f\"Iteration: {n_iterations}, average loss: {curr_loss_avg}\")\n",
    "    \n",
    "print(f\"{n_iterations} iterations have been performed. The average loss is {prev_loss_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9f4ba-1aa1-4c82-a1de-f07c972ef6fc",
   "metadata": {},
   "source": [
    "### 3.3. Train and validation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a79524-4663-49f2-a2c5-0f52cd9e94bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_error_avg = 0\n",
    "val_error_avg = 0\n",
    "\n",
    "for node in G_FMI_with_edges.nodes:\n",
    "    # Calculate training error.\n",
    "    X_train = torch.tensor(G_FMI_with_edges.nodes[node]['X_train'], dtype=torch.float32)\n",
    "    y_train = G_FMI_with_edges.nodes[node]['y_train']\n",
    "    y_train_pred = G_FMI_with_edges.nodes[node]['model'](X_train).detach().numpy()\n",
    "    train_error_avg += mean_squared_error(y_train, y_train_pred)\n",
    "    \n",
    "    # Calculate validation error.\n",
    "    X_val = torch.tensor(G_FMI_with_edges.nodes[node]['X_val'], dtype=torch.float32)\n",
    "    y_val = G_FMI_with_edges.nodes[node]['y_val']\n",
    "    y_val_pred = G_FMI_with_edges.nodes[node]['model'](X_val).detach().numpy()\n",
    "    val_error_avg += mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "train_error_avg /= n_stations\n",
    "val_error_avg /= n_stations\n",
    "\n",
    "print(f\"The average training error is {train_error_avg}\")\n",
    "print(f\"The average validation error is {val_error_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64522c35-4538-4d5a-9ba9-36a9a5f838ce",
   "metadata": {},
   "source": [
    "## 4. Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363c385-7dc0-495a-b987-a13e38ff75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if val_error_avg <= 25:\n",
    "    n_points = 11\n",
    "elif val_error_avg <= 30:\n",
    "    n_points = 5.5\n",
    "else:\n",
    "    n_points = 0\n",
    "    \n",
    "print(f\"You will recive {n_points} points for this assignment.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
