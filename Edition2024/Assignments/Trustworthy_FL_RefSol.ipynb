{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b78fe65-6ede-4404-a978-65344213f0dd",
   "metadata": {},
   "source": [
    "# Reference Solution for Assignment \"Trustworthy FL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee7f36-4fc8-4890-ab3f-dcf1daaa6ed6",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f23f50-f4a2-456f-9666-67119fd840cc",
   "metadata": {},
   "source": [
    "### 1.1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263c7cd-2a3b-49a0-b534-34168954e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules.\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import networkx as nx \n",
    "\n",
    "# Submodules\n",
    "import matplotlib.pyplot as plt \n",
    "from numpy import linalg as LA\n",
    "\n",
    "# Methods\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3fd87d-b620-4a83-90cd-4aec992eacc6",
   "metadata": {},
   "source": [
    "### 1.2 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48746b3a-0a88-4591-965f-679803f79cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function generates a scatter plot of nodes (=FMI stations) using \n",
    "# latitude and longitude as coordinates. \n",
    "def plotFMI(G_FMI):    \n",
    "    # Get the coordinates of the stations.\n",
    "    coords = np.array([G_FMI.nodes[node]['coord'] for node in G_FMI.nodes])\n",
    "    \n",
    "    # Draw nodes\n",
    "    for node in G_FMI.nodes:\n",
    "        plt.scatter(coords[node,1], coords[node,0], color='black', s=4, zorder=5)  # zorder ensures nodes are on top of edges\n",
    "        plt.text(coords[node,1]+0.1, coords[node,0]+0.2, str(node), fontsize=8, ha='center', va='center', color='black', fontweight='bold')\n",
    "    # Draw edges\n",
    "    for edge in G_FMI.edges:\n",
    "        plt.plot([coords[edge[0],1],coords[edge[1],1]], [coords[edge[0],0],coords[edge[1],0]], linestyle='-', color='gray', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('longitude')\n",
    "    plt.ylabel('latitude')\n",
    "    plt.title('FMI stations')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# The function connects each FMI station with \n",
    "# the nearest neighbours. \n",
    "def add_edges(graph, numneighbors=4):\n",
    "    # Get the coordinates of the stations.\n",
    "    coords = np.array([G_FMI.nodes[node]['coord'] for node in G_FMI.nodes])\n",
    "    \n",
    "    A = kneighbors_graph(coords, numneighbors, mode='connectivity', include_self=False)\n",
    "    nrnodes = len(graph.nodes)\n",
    "    for iter_i in range(nrnodes): \n",
    "        for iter_ii in range(nrnodes): \n",
    "            if iter_i != iter_ii : \n",
    "                if A[iter_i,iter_ii]> 0 :\n",
    "                    graph.add_edge(iter_i, iter_ii)\n",
    "    return graph\n",
    "\n",
    "# The function below extracts a feature and label from each row \n",
    "# of dataframe df. Each row is expected to hold a FMI weather \n",
    "# measurement with cols \"Latitude\", \"Longitude\", \"temp\", \"Timestamp\". \n",
    "# Returns numpy arrays X, y.\n",
    "def ExtractFeatureMatrixLabelVector(data):\n",
    "    nrfeatures = 7 \n",
    "    nrdatapoints = len(data)\n",
    "    \n",
    "    # We build the feature matrix X (each of its rows hold the features of a data point) \n",
    "    # and the label vector y (whose entries hold the labels of data points).\n",
    "    X = np.zeros((nrdatapoints, nrfeatures))\n",
    "    y = np.zeros((nrdatapoints, 1))\n",
    "\n",
    "    # Iterate over all rows in dataframe and create corresponding feature vector and label. \n",
    "    for ind in range(nrdatapoints):\n",
    "        # Latitude of FMI station, normalized by 100. \n",
    "        lat = float(data['Latitude'].iloc[ind])/100\n",
    "        # Longitude of FMI station, normalized by 100.\n",
    "        lon = float(data['Longitude'].iloc[ind])/100\n",
    "        # Temperature value of the data point.\n",
    "        tmp = data['temp'].iloc[ind]\n",
    "        # Read the date and time of the temperature measurement. \n",
    "        date_object = datetime.strptime(data['Timestamp'].iloc[ind], '%Y-%m-%d %H:%M:%S')\n",
    "        # Extract year, month, day, hour, and minute. Normalize these values \n",
    "        # to ensure that the features are in range [0,1].\n",
    "        year = float(date_object.year)/2025\n",
    "        month = float(date_object.month)/13\n",
    "        day = float(date_object.day)/32\n",
    "        hour = float(date_object.hour)/25\n",
    "        minute = float(date_object.minute)/61\n",
    "        \n",
    "        # Store the data point's features and a label.\n",
    "        X[ind,:] = [lat, lon, year, month, day, hour, minute]\n",
    "        y[ind,:] = tmp\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf67aa04-6a6b-4e5f-8e46-c24f0f126e20",
   "metadata": {},
   "source": [
    "### 1.3 Some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf55566-4d7a-4df5-b70b-841be35397cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the random seed to be used everywhere.\n",
    "seed = 4740"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc2a1d-1a87-48c6-983d-1406b573b0e2",
   "metadata": {},
   "source": [
    "## 2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ecad74-6015-4630-b06f-3450e40244a4",
   "metadata": {},
   "source": [
    "### 2.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf374bf-aa29-42de-bcc8-d6af189dca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the weather measurements.\n",
    "data = pd.read_csv('Assignment_MLBasicsData.csv')\n",
    "\n",
    "# We consider each temperature measurement (=a row in dataframe) as a \n",
    "# separate data point.\n",
    "\n",
    "# Define the numbers of data points, the unique stations, and features. \n",
    "num_stations = len(data.name.unique())\n",
    "num_datapoints = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855fd66f-b682-46a1-a6ef-0e6663b959e4",
   "metadata": {},
   "source": [
    "### 2.2 Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2f974-e8e6-4545-b0c2-f62cd77f7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels from the FMI data.\n",
    "X, y = ExtractFeatureMatrixLabelVector(data)\n",
    "\n",
    "print(f\"The created feature matrix contains {np.shape(X)[0]} entries of {np.shape(X)[1]} features each.\")\n",
    "print(f\"The created label vector contains {np.shape(y)[0]} measurements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e587e0-a4e9-4ca1-9f2f-98737adee944",
   "metadata": {},
   "source": [
    "### 2.3 Empirical graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3255cd-1cb2-49c6-bddc-efae244b6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a networkX graph\n",
    "G_FMI = nx.Graph()\n",
    "\n",
    "# Add a one node per station\n",
    "G_FMI.add_nodes_from(range(0, num_stations))\n",
    "\n",
    "for i, station in enumerate(data.name.unique()):\n",
    "    # Extract data of a certain station\n",
    "    station_data = data[data.name==station]\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X_local, y_local = ExtractFeatureMatrixLabelVector(station_data)\n",
    "    \n",
    "    # Split the dataset into training and validation set. \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_local, y_local, test_size=0.2, random_state=seed)\n",
    "\n",
    "    localsamplesize = len(y)\n",
    "    G_FMI.nodes[i]['sample_size'] = localsamplesize # The number of measurements of the i-th weather station\n",
    "    G_FMI.nodes[i]['name'] = station # The name of the i-th weather station\n",
    "    G_FMI.nodes[i]['coord'] = (station_data.Latitude.unique()[0], station_data.Longitude.unique()[0]) # The coordinates of the i-th weather station\n",
    "    G_FMI.nodes[i]['X_train'] = X_train # The training feature matrix for local dataset at node i\n",
    "    G_FMI.nodes[i]['y_train'] = y_train  # The training label vector for local dataset at node i\n",
    "    G_FMI.nodes[i]['X_val'] = X_val # The training feature matrix for local dataset at node i\n",
    "    G_FMI.nodes[i]['y_val'] = y_val  # The training label vector for local dataset at node i\n",
    "    G_FMI.nodes[i]['weights'] = np.zeros((7, 1)) # The weight vector for local dataset at node i\n",
    "    G_FMI.nodes[i]['epsilon'] = np.zeros_like(y_local) # The perturbation for local dataset at node i\n",
    "\n",
    "# Add edges between each station and its nearest neighbors.\n",
    "# NOTE: the node degree might be different for different nodes.\n",
    "numneighbors = 4\n",
    "G_FMI = add_edges(G_FMI, numneighbors=numneighbors)\n",
    "print(\"The empirical graph is connected:\", nx.is_connected(G_FMI))\n",
    "\n",
    "# Visualize the empirical graph.\n",
    "plotFMI(G_FMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099d15fa-5fce-455f-8a13-0314f60a4f33",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475ad9c-5db4-4f2a-916e-7db49c1150e4",
   "metadata": {},
   "source": [
    "### 3.1 FedGD without perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d32ff-21ce-4336-903c-799802e79fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedGD(graph_FMI, alpha=0.5, l_rate=0.1, max_iter=1000):\n",
    "    # Copy the nodes to a new graph.\n",
    "    graph = graph_FMI.copy()\n",
    "    \n",
    "    # Initialize all weight vectors with zeros \n",
    "    for node in graph.nodes:\n",
    "        graph.nodes[node]['weights'] = np.zeros((7, 1))\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        # Iterate over all nodes.\n",
    "        for current_node in graph.nodes:\n",
    "\n",
    "            # Extract the training data from the current node.\n",
    "            X_train = graph.nodes[current_node]['X_train']\n",
    "            y_train = graph.nodes[current_node]['y_train']\n",
    "            w_current = graph.nodes[current_node]['weights']\n",
    "            training_size = len(y_train)\n",
    "\n",
    "            # Compute the first term of the Equation 5.8.\n",
    "            term_1 = (2/training_size) * X_train.T.dot(y_train - X_train.dot(w_current))\n",
    "            # Compute the second term of the Equation 5.8\n",
    "            # by receiving neighbors' weight vectors.\n",
    "            term_2 = 0\n",
    "            neighbors = list(graph.neighbors(current_node))\n",
    "            for neighbor in neighbors:\n",
    "                w_neighbor = graph.nodes[neighbor]['weights']\n",
    "                term_2 += w_neighbor - w_current\n",
    "            term_2 *= 2*alpha\n",
    "            # Equation 5.8\n",
    "            w_updated = w_current + l_rate * (term_1 + term_2)\n",
    "\n",
    "            # Update the current weight vector but do not overwrite the \n",
    "            # \"weights\" attribute as we need to do all updates synchronously, i.e., \n",
    "            # using the previous local params. \n",
    "\n",
    "            graph.nodes[current_node]['newweights'] = w_updated\n",
    "\n",
    "        # After computing the new localparmas for each node, we now update \n",
    "        # the node attribute 'weights' for all nodes. \n",
    "        for node in graph.nodes: \n",
    "            graph.nodes[node]['weights'] = graph.nodes[node]['newweights']\n",
    "            \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e0f77-2a8e-49e6-a1bc-1ece044ac1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform Federated Gradient Descent with default parameters.\n",
    "G_FMI_FedGD = FedGD(G_FMI)\n",
    "\n",
    "# Extract the updated local models' parameters. \n",
    "weights_original_data = np.array([G_FMI_FedGD.nodes[node]['weights'] for node in G_FMI_FedGD.nodes])\n",
    "\n",
    "# Sanity check. \n",
    "print(f'The shape of the original weights is {weights_original_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc1f021-1eee-4bf2-a905-08d7a78e2afc",
   "metadata": {},
   "source": [
    "### 3.2 Student task #1 - The effect of perturbations on the local model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a813122-5e19-47a2-ba13-e2acef22020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedGD_perturbed(graph_FMI, alpha=0.5, l_rate=0.1, max_iter=1000, variance=1, mean=0, seed=4740):\n",
    "    # Define the random seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Copy the nodes to a new graph.\n",
    "    graph = graph_FMI.copy()\n",
    "    \n",
    "    # Progress log.\n",
    "    print(f'Train on the perturbed data with mean = {mean} and variance = {variance}...')\n",
    "\n",
    "    # Initialize all weight vectors with zeros \n",
    "    for node in graph.nodes:\n",
    "        graph.nodes[node]['weights'] = np.zeros((7, 1))\n",
    "\n",
    "    # Add perturbations.\n",
    "    # Epsilon ~ N(mean, variance)\n",
    "    for node in graph.nodes:\n",
    "        trainsize = len(graph.nodes[node]['y_train'])\n",
    "        graph.nodes[node]['epsilon'] = mean + np.random.randn(trainsize, 1) * variance\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # Iterate over all nodes.\n",
    "        for current_node in graph.nodes:\n",
    "\n",
    "            # Extract the training data from the current node.\n",
    "            X_train = graph.nodes[current_node]['X_train']\n",
    "            y_train = graph.nodes[current_node]['y_train'] + graph.nodes[current_node]['epsilon']\n",
    "            w_current = graph.nodes[current_node]['weights']\n",
    "            training_size = len(y_train)\n",
    "\n",
    "            # Compute the first term of the Equation 5.8.\n",
    "            term_1 = (2/training_size) * X_train.T.dot(y_train - X_train.dot(w_current))\n",
    "            # Compute the second term of the Equation 5.8\n",
    "            # by receiving neighbors' weight vectors.\n",
    "            term_2 = 0\n",
    "            neighbors = list(graph.neighbors(current_node))\n",
    "            for neighbor in neighbors:\n",
    "                w_neighbor = graph.nodes[neighbor]['weights']\n",
    "                term_2 += w_neighbor - w_current\n",
    "            term_2 *= 2*alpha\n",
    "            # Equation 5.8\n",
    "            w_updated = w_current + l_rate * (term_1 + term_2)\n",
    "\n",
    "            # Update the current weight vector but do not overwrite the \n",
    "            # \"weights\" attribute as we need to do all updates synchronously, i.e., \n",
    "            # using the previous local params \n",
    "\n",
    "            graph.nodes[current_node]['newweights'] = w_updated\n",
    "\n",
    "        # after computing the new localparmas for each node, we now update \n",
    "        # the node attribute 'weights' for all nodes \n",
    "        for node in graph.nodes: \n",
    "            graph.nodes[node]['weights'] = graph.nodes[node]['newweights']\n",
    "            \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea5953-7608-4d44-bfd2-2215198b526f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the variances to test.\n",
    "variances = np.arange(0, 56, 5)\n",
    "\n",
    "# Define the storage for the sums of distances\n",
    "# between the weight vectors.\n",
    "sum_distances = np.zeros(len(variances))\n",
    "\n",
    "# Try different variances.\n",
    "for n_variance, variance in enumerate(variances):\n",
    "    # Update the local models' parameters with perturbed labels.\n",
    "    # \n",
    "    G_FMI_FedGD_perturbed = FedGD_perturbed(G_FMI, variance=variance)\n",
    "    weights_perturbed_data = np.array([G_FMI_FedGD_perturbed.nodes[node]['weights'] \n",
    "                                       for node in G_FMI_FedGD_perturbed.nodes])\n",
    "    sum_distances[n_variance] = np.sum(LA.norm((weights_original_data - weights_perturbed_data), axis=1))\n",
    "\n",
    "# Plot the results.\n",
    "plt.plot(variances, sum_distances)\n",
    "plt.xlabel(\"The variances of perturbations\")\n",
    "plt.ylabel(\"Sum of distances\")\n",
    "plt.title(\"The effect of perturbations on the local model parameters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb1bf9-2fc0-4164-9ae9-1603918dc855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the means to test.\n",
    "means = np.arange(0, 56, 5)\n",
    "\n",
    "# Define the storage for the sums of distances\n",
    "# between the weight vectors.\n",
    "sum_distances = np.zeros(len(means))\n",
    "\n",
    "# Try different means.\n",
    "for n_mean, mean in enumerate(means):\n",
    "    # Update the local models' parameters with perturbed labels.\n",
    "    G_FMI_FedGD_perturbed = FedGD_perturbed(G_FMI, mean=mean)\n",
    "    weights_perturbed_data = np.array([G_FMI_FedGD_perturbed.nodes[node]['weights'] \n",
    "                                       for node in G_FMI_FedGD_perturbed.nodes])\n",
    "    sum_distances[n_mean] = np.sum(LA.norm((weights_original_data - weights_perturbed_data), axis=1))\n",
    "\n",
    "# Plot the results.\n",
    "plt.plot(means, sum_distances)\n",
    "plt.xlabel(\"The means of perturbations\")\n",
    "plt.ylabel(\"Sum of distances\")\n",
    "plt.title(\"The effect of perturbations on the local model parameters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e4cfa-3904-4440-b4e7-20d4d3019c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
