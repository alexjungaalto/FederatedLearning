{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e699af84-e727-4f56-af86-e3babb05b605",
   "metadata": {},
   "source": [
    "# Coding Assignment - \"ML Basics\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68cf3d2-45cb-47c1-a8ee-f7421da05d3b",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32207fbc-2315-4954-a0b2-ffc241791801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef4f23-7b73-478a-ab82-f61893b8ca49",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15a0dd-8689-4cc5-a797-050e775586d1",
   "metadata": {},
   "source": [
    "### 2.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2adce41f-2df7-4abe-bf42-49ea1105d8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First data point:\n",
      "Unnamed: 0                              0\n",
      "Latitude                         69.04277\n",
      "Longitude                        20.85091\n",
      "Timestamp             2023-12-31 18:00:00\n",
      "temp                                -16.5\n",
      "name          Enontekiö Kilpisjärvi Saana\n",
      "Name: 0, dtype: object\n",
      "\n",
      "******************************\n",
      "\n",
      "Another data point:\n",
      "Unnamed: 0                        13\n",
      "Latitude                      69.757\n",
      "Longitude                     27.012\n",
      "Timestamp        2023-12-31 13:00:00\n",
      "temp                           -26.3\n",
      "name          Utsjoki Kevo Kevojärvi\n",
      "Name: 13, dtype: object\n",
      "\n",
      "******************************\n",
      "\n",
      "Unnormalized features of the first data point: \n",
      "Latitude: 69.04277\n",
      "Longitude: 20.85091\n",
      "Year: 2023.0\n",
      "Month: 12.0\n",
      "Day: 31.0\n",
      "Hour: 18.0\n",
      "Minute: 0.0\n",
      "\n",
      "******************************\n",
      "\n",
      "Normalized features of the first data point: \n",
      "Latitude: 0.6904277000000001\n",
      "Longitude: 0.2085091\n",
      "Year: 0.9990123456790123\n",
      "Month: 0.9230769230769231\n",
      "Day: 0.96875\n",
      "Hour: 0.72\n",
      "Minute: 0.0\n",
      "\n",
      "******************************\n",
      "\n",
      "Label of the first data point: -16.5\n"
     ]
    }
   ],
   "source": [
    "# Import the weather measurements.\n",
    "data = pd.read_csv('Assignment_MLBasicsData.csv')\n",
    "\n",
    "# We consider each temperature measurement (=a row in dataframe data) \n",
    "# as a separate data point.\n",
    "# Determine the total number of data points stored in csv file.\n",
    "nrdatapoints = len(data)\n",
    "\n",
    "# Print out the first data point (first row).\n",
    "print(\"First data point:\")\n",
    "print(data.iloc[0])\n",
    "print(\"\\n******************************\\n\")\n",
    "\n",
    "# Here is another data point. \n",
    "print(\"Another data point:\")\n",
    "print(data.iloc[13])\n",
    "print(\"\\n******************************\\n\")\n",
    "\n",
    "# We use normalized values of \n",
    "# latitude, longitude, year, mon, day, hour, minute (as float values) \n",
    "# as features of a data point.\n",
    "nrfeatures = 7 \n",
    "\n",
    "# The code snippet below extracts the features of the first data point (first row in dataframe data).\n",
    "date_object = datetime.strptime(data['Timestamp'].iloc[0], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Extract individual components.\n",
    "latitude = data[\"Latitude\"].iloc[0]\n",
    "longitude = data[\"Longitude\"].iloc[0]\n",
    "year = float(date_object.year)\n",
    "month = float(date_object.month)\n",
    "day = float(date_object.day)\n",
    "hour = float(date_object.hour)\n",
    "minute = float(date_object.minute)\n",
    "\n",
    "print(\"Unnormalized features of the first data point: \")\n",
    "print(f\"Latitude: {latitude}\")\n",
    "print(f\"Longitude: {longitude}\")\n",
    "print(f\"Year: {year}\")\n",
    "print(f\"Month: {month}\")\n",
    "print(f\"Day: {day}\")\n",
    "print(f\"Hour: {hour}\")\n",
    "print(f\"Minute: {minute}\")\n",
    "print(\"\\n******************************\\n\")\n",
    "\n",
    "print(\"Normalized features of the first data point: \")\n",
    "print(f\"Latitude: {latitude/100}\")\n",
    "print(f\"Longitude: {longitude/100}\")\n",
    "print(f\"Year: {year/2025}\")\n",
    "print(f\"Month: {month/13}\")\n",
    "print(f\"Day: {day/32}\")\n",
    "print(f\"Hour: {hour/25}\")\n",
    "print(f\"Minute: {minute/61}\")\n",
    "print(\"\\n******************************\\n\")\n",
    "\n",
    "# We choose the temperature as the label (quantity of interest) of a data point.\n",
    "print(\"Label of the first data point:\", data[\"temp\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a9fa1-46d6-4123-a941-9bb395307a57",
   "metadata": {},
   "source": [
    "### 2.2 Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da06099-bd6b-4b1e-85b5-926aafec03f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The created feature matrix contains 19768 entries of 7 features each.\n",
      "The created label vector contains 19768 measurements.\n"
     ]
    }
   ],
   "source": [
    "# We next build the feature matrix X (each of its rows hold the features of a data point) \n",
    "# and the label vector y (whose entries hold the labels of data points).\n",
    "X = np.zeros((nrdatapoints, nrfeatures))\n",
    "y = np.zeros((nrdatapoints, 1))\n",
    "\n",
    "# Iterate over all rows in dataframe and create corresponding feature vector and label. \n",
    "for ind in data.index:\n",
    "    # Latitude of FMI station, normalized by 100. \n",
    "    lat = float(data['Latitude'].iloc[ind]) / 100\n",
    "    \n",
    "    # Longitude of FMI station, normalized by 100.\n",
    "    lon = float(data['Longitude'].iloc[ind]) / 100\n",
    "    \n",
    "    # Exctract the temperature value.\n",
    "    tmp = data['temp'].iloc[ind]\n",
    "    \n",
    "    # Read the date and time of the temperature measurement.\n",
    "    date_object = datetime.strptime(data['Timestamp'].iloc[ind], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Extract year, month, day, hour, minute, and second. \n",
    "    # Normalize these values to ensure features are in range [0,1].\n",
    "    year = float(date_object.year) / 2025\n",
    "    month = float(date_object.month) / 13\n",
    "    day = float(date_object.day) / 32\n",
    "    hour = float(date_object.hour) / 25\n",
    "    minute = float(date_object.minute) / 61\n",
    "    \n",
    "    # Store the data point's features and a label.\n",
    "    X[ind,:] = [lat, lon, year, month, day, hour, minute]\n",
    "    y[ind,:] = tmp\n",
    "\n",
    "print(f\"The created feature matrix contains {np.shape(X)[0]} entries of {np.shape(X)[1]} features each.\")\n",
    "print(f\"The created label vector contains {np.shape(y)[0]} measurements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163ebeb-424b-4bc1-aa57-eab4f6b75bff",
   "metadata": {},
   "source": [
    "### 2.3 Training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe96a85c-7a71-4126-af3b-041fdf77f1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set consists of 100 data points.\n",
      "The validation set consists of 19668 data points.\n"
     ]
    }
   ],
   "source": [
    "# Define the number of data points used for training set.\n",
    "trainsize = 100\n",
    "\n",
    "# Split the dataset into training and validation set. \n",
    "Xtrain = X[:trainsize,:] \n",
    "Xval = X[trainsize:] \n",
    "ytrain = y[:trainsize] \n",
    "yval = y[trainsize:] \n",
    "\n",
    "print(f\"The training set consists of {np.shape(Xtrain)[0]} data points.\")\n",
    "print(f\"The validation set consists of {np.shape(Xval)[0]} data points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b363b2a-28c3-4e19-ae4b-ad675371643f",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb00ec-c894-4ec5-a41a-b90bc994fef6",
   "metadata": {},
   "source": [
    "### 3.1 Student task #1 - Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583b0b4c-14b8-4356-b7c6-e7a0424155a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m####################TODO####################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# TODO: Train a linear model, using the LinearRegression class of the scikit-learn package, \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#       on the training set and determine the resulting training and validation errors.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Etrain = \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Eval =\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m*************** Linear Regression Diagnosis ***************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################TODO####################\n",
    "# TODO: Train a linear model, using the LinearRegression class of the scikit-learn package, \n",
    "#       on the training set and determine the resulting training and validation errors.\n",
    "\n",
    "raise NotImplementedError\n",
    "# Etrain = \n",
    "# Eval =\n",
    "\n",
    "print(\"\\n*************** Linear Regression Diagnosis ***************\")\n",
    "print(\"Training error:\", Etrain)\n",
    "print(\"Validation error:\", Eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dad8c8-dab0-427d-ac5e-45457e7d3424",
   "metadata": {},
   "source": [
    "### 3.2 Student task #2 - Polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "915b45be-6199-42ba-aefc-eeb2eb625fec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m maxdegreevals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m####################TODO####################\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# TODO: Train and validate a linear model for different choices for the maximal\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#       polynomial degree used.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#       Store the obtained training and validation errors for plotting. \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# trainerr = \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# valerr = \u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Plot the # Plot the training and validation errors\u001b[39;00m\n\u001b[1;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(maxdegreevals, np\u001b[38;5;241m.\u001b[39mhstack([trainerr, valerr]))\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the polynomial degrees.\n",
    "maxdegreevals = [1, 2, 3]\n",
    "\n",
    "####################TODO####################\n",
    "# TODO: Train and validate a linear model for different choices for the maximal\n",
    "#       polynomial degree used.\n",
    "#       Store the obtained training and validation errors for plotting. \n",
    "\n",
    "raise NotImplementedError\n",
    "# trainerr = \n",
    "# valerr = \n",
    "    \n",
    "# Plot the training and validation errors.\n",
    "plt.plot(maxdegreevals, np.hstack([trainerr, valerr]))\n",
    "plt.legend([\"training error\",\"validation error\"])\n",
    "plt.xlabel(r'$d_{\\rm max}$')\n",
    "plt.ylabel('ln(MSE)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503820e-d01e-45ca-9f07-5d858aed57dc",
   "metadata": {},
   "source": [
    "### 3.3 Student task #3 - Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d4dccb4-e56b-4eb4-a9e4-e4fad7e272a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m poly_degree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m####################TODO####################\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# TODO: Using a fixed value for the polynomial degree for the feature augmentation step, \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#       train and validate a linear model using ridge regression (2.22) via the Ridge class. \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#       For each choice of alpha in (2.22), determine the resulting training and validation errors.\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# trainerr = \u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# valerr = \u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Plot the training and validation errors\u001b[39;00m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39mlog10(alphavals), trainerr)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Values for the GTVMin parameter alpha.\n",
    "GTVmin_parameter = np.array([1e-9, 5e-9, 1e-8, 1e-7,1e-6,5e-5]) \n",
    "# The input paramter 'alpha' for RidgeRegression class requires a scaling by the samplesize.\n",
    "alphavals = GTVmin_parameter * trainsize\n",
    "# The maximal degree of polynomial combinations of original features used to create more features.\n",
    "poly_degree = 3\n",
    "\n",
    "####################TODO####################\n",
    "# TODO: Using a fixed value for the polynomial degree for the feature augmentation step, \n",
    "#       train and validate a linear model using ridge regression (2.22) via the Ridge class. \n",
    "#       For each choice of alpha in (2.22), determine the resulting training and validation errors.\n",
    "\n",
    "raise NotImplementedError\n",
    "# trainerr = \n",
    "# valerr = \n",
    "    \n",
    "# Plot the training and validation errors.\n",
    "plt.plot(np.log10(alphavals), trainerr)\n",
    "plt.plot(np.log10(alphavals), valerr)\n",
    "plt.legend(['training error', 'validation error'])\n",
    "plt.xlabel(r'${\\rm log} \\alpha$')\n",
    "plt.ylabel('ln(MSE)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
