{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assignment - \"Graph Learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# We will use networx objects to store empircial graphs, local datasets and models\n",
    "import networkx as nx \n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function generates a scatter plot of nodes (=FMI stations) using \n",
    "# latitude and longitude as coordinates. \n",
    "def plotFMI(G_FMI):\n",
    "    \n",
    "    # Get the coordinates of the stations.\n",
    "    coords = np.array([G_FMI.nodes[node]['coord'] for node in G_FMI.nodes])\n",
    "    \n",
    "    # Draw nodes\n",
    "    for node in G_FMI.nodes:\n",
    "        plt.scatter(coords[node,1], coords[node,0], color='black', s=4, zorder=5)  # zorder ensures nodes are on top of edges\n",
    "        plt.text(coords[node,1]+0.1, coords[node,0]+0.2, str(node), fontsize=8, ha='center', va='center', color='black', fontweight='bold')\n",
    "    # Draw edges\n",
    "    for edge in G_FMI.edges:\n",
    "        plt.plot([coords[edge[0],1],coords[edge[1],1]], [coords[edge[0],0],coords[edge[1],0]], linestyle='-', color='gray', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('longitude')\n",
    "    plt.ylabel('latitude')\n",
    "    plt.title('FMI stations')\n",
    "    plt.show()\n",
    "\n",
    "# The function below extracts a feature and label from each row \n",
    "# of dataframe df. Each row is expected to hold a FMI weather \n",
    "# measurement with cols \"Latitude\", \"Longitude\", \"temp\", \"Timestamp\". \n",
    "# Returns numpy arrays X, y.\n",
    "def ExtractFeatureMatrixLabelVector(data):\n",
    "    nrfeatures = 7 \n",
    "    nrdatapoints = len(data)\n",
    "    \n",
    "    # We build the feature matrix X (each of its rows hold the features of a data point) \n",
    "    # and the label vector y (whose entries hold the labels of data points).\n",
    "    X = np.zeros((nrdatapoints, nrfeatures))\n",
    "    y = np.zeros((nrdatapoints, 1))\n",
    "\n",
    "    # Iterate over all rows in dataframe and create corresponding feature vector and label. \n",
    "    for ind in range(nrdatapoints):\n",
    "        # Latitude of FMI station, normalized by 100. \n",
    "        lat = float(data['Latitude'].iloc[ind])/100\n",
    "        # Longitude of FMI station, normalized by 100.\n",
    "        lon = float(data['Longitude'].iloc[ind])/100\n",
    "        # Temperature value of the data point.\n",
    "        tmp = data['temp'].iloc[ind]\n",
    "        # Read the date and time of the temperature measurement. \n",
    "        date_object = datetime.strptime(data['Timestamp'].iloc[ind], '%Y-%m-%d %H:%M:%S')\n",
    "        # Extract year, month, day, hour, and minute. Normalize these values \n",
    "        # to ensure that the features are in range [0,1].\n",
    "        year = float(date_object.year)/2025\n",
    "        month = float(date_object.month)/13\n",
    "        day = float(date_object.day)/32\n",
    "        hour = float(date_object.hour)/25\n",
    "        minute = float(date_object.minute)/61\n",
    "        \n",
    "        # Store the data point's features and a label.\n",
    "        X[ind,:] = [lat, lon, year, month, day, hour, minute]\n",
    "        y[ind,:] = tmp\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the weather measurements.\n",
    "data = pd.read_csv('Assignment_MLBasicsData.csv')\n",
    "\n",
    "# We consider each temperature measurement (=a row in dataframe) as a \n",
    "# separate data point.\n",
    "# Get the numbers of data points and the unique stations.\n",
    "num_stations = len(data.name.unique())\n",
    "num_datapoints = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We next build the feature matrix X (each of its rows hold the features of a data point) \n",
    "# and the label vector y (whose entries hold the labels of data points).\n",
    "X, y = ExtractFeatureMatrixLabelVector(data)\n",
    "\n",
    "print(f\"The created feature matrix contains {np.shape(X)[0]} entries of {np.shape(X)[1]} features each.\")\n",
    "print(f\"The created label vector contains {np.shape(y)[0]} measurements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Empirical graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a networkX graph\n",
    "G_FMI = nx.Graph()\n",
    "\n",
    "# Add a one node per station\n",
    "G_FMI.add_nodes_from(range(0, num_stations))\n",
    "\n",
    "for i, station in enumerate(data.name.unique()):\n",
    "    # Extract data of a certain station\n",
    "    station_data = data[data.name==station]\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X_node, y_node = ExtractFeatureMatrixLabelVector(station_data)\n",
    "\n",
    "    localsamplesize = len(y_node)\n",
    "    G_FMI.nodes[i]['samplesize'] = localsamplesize # The number of measurements of the i-th weather station\n",
    "    G_FMI.nodes[i]['name'] = station # The name of the i-th weather station\n",
    "    G_FMI.nodes[i]['coord'] = np.array([station_data.Latitude.unique()[0], station_data.Longitude.unique()[0]]) # The coordinates of the i-th weather station\n",
    "    G_FMI.nodes[i]['X'] = X_node # The feature matrix for local dataset at node i\n",
    "    G_FMI.nodes[i]['y'] = y_node  # The  label vector for local dataset at node i\n",
    "    G_FMI.nodes[i]['z'] = None # The representation vector for local dataset at node i\n",
    "\n",
    "# Visualize the empirical graph.\n",
    "plotFMI(G_FMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The discrepancy measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#    1. graph_FMI (class: networkx.classes.graph.Graph) - a graph to which the edges will be added.\n",
    "#    2. node_degree (class: int) - the minimum number of neighbors (the minimum node degree).\n",
    "# Outputs:\n",
    "#    1. graph (class: networkx.classes.graph.Graph) - a graph with added edges.\n",
    "def add_edges(graph_FMI, node_degree):\n",
    "    graph = graph_FMI.copy()\n",
    "    \n",
    "    for node in graph.nodes:\n",
    "            \n",
    "        # TODO: Extract the representation vector of the node.\n",
    "        # z_node = \n",
    "        raise NotImplementedError\n",
    "        \n",
    "        # Create storages for discrepancies and the corresponding neighbors.\n",
    "        d_mins = np.full(shape=node_degree, fill_value=1e10)\n",
    "        edges = np.full(shape=(node_degree, 2), fill_value=(node, -1))\n",
    "    \n",
    "        for potential_neighbor in graph.nodes:\n",
    "            if potential_neighbor != node:\n",
    "                \n",
    "                # TODO: Extract the representation vecotr of the potential neighbor.\n",
    "                # z_neighbor = \n",
    "                raise NotImplementedError\n",
    "                \n",
    "                # TODO: Calculate the discrepancy.\n",
    "                # d = \n",
    "                raise NotImplementedError\n",
    "\n",
    "                # TODO: Find the max discrepancy so far.\n",
    "                #       Also, find its index to access the \n",
    "                #       corresponding neighbor later.\n",
    "                # d_max_idx = \n",
    "                # d_max = \n",
    "                raise NotImplementedError\n",
    "                \n",
    "                if d < d_max:\n",
    "                    # TODO: Store the calculated discrepancy and\n",
    "                    #       the corresponding neighbor.\n",
    "                    # d_mins[d_max_idx] = \n",
    "                    # edges[d_max_idx][1] = \n",
    "                    raise NotImplementedError\n",
    "\n",
    "        # Add edges from the given pairs of connected nodes.\n",
    "        graph.add_edges_from(edges) \n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Student task #1 - The average temperature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edges_avg_temp(graph_FMI, n_neighbors): \n",
    "    # Copy the nodes to a new graph.\n",
    "    graph = graph_FMI.copy()\n",
    "\n",
    "    ####################TODO####################\n",
    "    # TODO: 1. Create the representation vector for each node.\n",
    "    #       2. Add the edges based on the representation vectors.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return graph\n",
    "\n",
    "# Visualize an example graph with \n",
    "# minimum node degree = 1. \n",
    "plotFMI(add_edges_avg_temp(G_FMI, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Student task #2 - The difference in GMM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edges_GMM_param(graph_FMI, GMM_seed, n_neighbors):\n",
    "    # Copy the nodes to a new graph.\n",
    "    graph = graph_FMI.copy()\n",
    "\n",
    "    # Define the number components for the GMM. \n",
    "    n_components = 2\n",
    "\n",
    "    ####################TODO####################\n",
    "    # TODO: 1. Create the representation vector for each node (see \"NOTE\").\n",
    "    #       2. Add the edges based on the representation vectors.\n",
    "    # NOTE: Use the same GMM structure as in the \"FL Flavors\" assignment. \n",
    "    #       You can copy-paste your previous implementation.\n",
    "    raise NotImplementedError\n",
    "\n",
    "    # Add edges.\n",
    "    graph = add_edges(graph, n_neighbors)\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Visualize an example graph. \n",
    "plotFMI(add_edges_GMM_param(G_FMI, 4740, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Student task #3 - The gradient of the average squared error loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edges_gradient_loss(graph_FMI, n_neighbors):\n",
    "    # Copy the nodes to a new graph.\n",
    "    graph = graph_FMI.copy()\n",
    "\n",
    "    ####################TODO####################\n",
    "    # TODO: 1. Create the representation vector for each node (see \"NOTE\").\n",
    "    #       2. Add the edges based on the representation vectors.\n",
    "    # NOTE: 1. Fit a linear regression to the whole dataset\n",
    "    #          and extract the model's parameters.\n",
    "    #       2. Calculate the gradient of the average squared error loss for each node\n",
    "    #          according to the Section 7.5 in the Lecture Notes .\n",
    "    raise NotImplementedError\n",
    "\n",
    "    # Add edges.\n",
    "    graph = add_edges(graph, n_neighbors)\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Visualize an example graph. \n",
    "plotFMI(add_edges_gradient_loss(G_FMI, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 FedGD (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedGD(graph_FMI, split_seed):\n",
    "    graph = graph_FMI.copy()\n",
    "    \n",
    "    # Define hyperparameters.\n",
    "    max_iter = 1000 # The number of gradient steps.\n",
    "    alpha = 0.5 # Alpha parameter.\n",
    "    l_rate = 0.1 # The learning rate.\n",
    "    \n",
    "    # Create the storages for the training and validation errors.\n",
    "    num_stations = len(graph.nodes)\n",
    "    train_errors = np.zeros(num_stations)\n",
    "    val_errors = np.zeros(num_stations)\n",
    "    \n",
    "    # TODO: Use your previous implementation of\n",
    "    #       the FedGD algorithm. \n",
    "    #       See coding assignment \"FL Algorithms\".\n",
    "    # HINT: 1. Split the local datasets into training and validation sets.\n",
    "    #       2. Initialize all weight vectors with zeros.\n",
    "    #       3. Perform FedGD on the local training sets. \n",
    "    #       4. Compute and store the training and validation errors\n",
    "    #          for each node.\n",
    "    raise NotImplementedError\n",
    "        \n",
    "    # Output the average training and validation errors.\n",
    "    return np.mean(train_errors), np.mean(val_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the random seed for\n",
    "# add_edges_GMM_param function.\n",
    "seed = 4740\n",
    "\n",
    "for num_neighbors in range(1, 11):\n",
    "    G_FMI_1 = add_edges_avg_temp(G_FMI, num_neighbors)\n",
    "    G_FMI_2 = add_edges_GMM_param(G_FMI, seed, num_neighbors)\n",
    "    G_FMI_3 = add_edges_gradient_loss(G_FMI, num_neighbors)\n",
    "    \n",
    "    # Print the results.\n",
    "    print(f\"The minimum number of neighbors is {num_neighbors}\")\n",
    "    print(f\"G_FMI_1 is connected: {nx.is_connected(G_FMI_1)}\")\n",
    "    print(f\"G_FMI_2 is connected: {nx.is_connected(G_FMI_2)}\")\n",
    "    print(f\"G_FMI_3 is connected: {nx.is_connected(G_FMI_3)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 FedGD errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the random seed for\n",
    "# add_edges_GMM_param and FedGD functions.\n",
    "seed = 4740\n",
    "\n",
    "# The minimum number of neighbors to connect with.\n",
    "num_neighbors = 1\n",
    "\n",
    "# Add edges.\n",
    "G_FMI_1 = add_edges_avg_temp(G_FMI, num_neighbors)\n",
    "G_FMI_2 = add_edges_GMM_param(G_FMI, seed, num_neighbors)\n",
    "G_FMI_3 = add_edges_gradient_loss(G_FMI, num_neighbors)\n",
    "\n",
    "# Apply the FedGD algorithm.\n",
    "G_FMI_1_train_error, G_FMI_1_val_error = FedGD(G_FMI_1, seed)\n",
    "G_FMI_2_train_error, G_FMI_2_val_error = FedGD(G_FMI_2, seed)\n",
    "G_FMI_3_train_error, G_FMI_3_val_error = FedGD(G_FMI_3, seed)\n",
    "\n",
    "# Print the results.\n",
    "print(f\"The seed is {seed}\")\n",
    "print(f\"The average training error for G_FMI_1: {G_FMI_1_train_error}\\nThe average validation error for G_FMI_1: {G_FMI_1_val_error}\\n\")\n",
    "print(f\"The average training error for G_FMI_2: {G_FMI_2_train_error}\\nThe average validation error for G_FMI_2: {G_FMI_2_val_error}\\n\")\n",
    "print(f\"The average training error for G_FMI_3: {G_FMI_3_train_error}\\nThe average validation error for G_FMI_3: {G_FMI_3_val_error}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
