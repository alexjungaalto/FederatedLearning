{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72fae605-9fd2-4867-89f9-109d0b01b264",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fc8239c00699f7d5b2696c16ef0a585",
     "grade": false,
     "grade_id": "cell-4a1cafd2e7b56a5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## CS-E4740 - Federated Learning D (Spring 25)\n",
    "\n",
    "# Assignment 5: FL Main Flavors\n",
    "\n",
    "### A. Pavlyuk, A. Jung, and ChatGPT\n",
    "\n",
    "<a id='varying_features'></a>\n",
    "<div class=\"alert alert-warning\">\n",
    "    <h2>Deadline: 14.04.2025</h2>\n",
    "</div>\n",
    "\n",
    "<a id='varying_features'></a><div class=\"alert alert-info\">\n",
    "\n",
    "## Learning Goals\n",
    "After completing the notebook, you should\n",
    "    \n",
    "- understand when and how to use vertical federated learning (FL),\n",
    "- understand when and how to use clustered FL.\n",
    "\n",
    "\n",
    "## Background Material\n",
    "\n",
    "1. Chapter 6 of [FLBook](https://github.com/alexjungaalto/FederatedLearning/blob/main/material/FLBook.pdf)\n",
    "\n",
    "## Notebook Structure\n",
    "1. The notebook consists of two parts: coding tasks (referred to as Task) and quiz questions (referred as Question). \n",
    "2. Both Tasks and Questions use a point-separated index X.Y, where X is the number of the notebook and Y is the number of the task/question in the X'th notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebf8bb-df9b-448a-ad72-466a563767ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e885e64e1f2150b81565f6c6a222d73",
     "grade": false,
     "grade_id": "cell-17e1540c5a1cbaff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d946dfb3-d872-4119-8d6b-31d43bca172f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c593a3b4b009b559d05e9273ca08f36d",
     "grade": false,
     "grade_id": "cell-b9fe206a7f43a8dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import copy # Provides shallow and deep copy operations for objects\n",
    "import numpy as np # NumPy for numerical computations and array manipulations\n",
    "import pandas as pd # Pandas for data manipulation and analysis\n",
    "from datetime import datetime # Handles date and time operations\n",
    "from numpy import linalg as LA # Linear algebra functions\n",
    "import matplotlib.pyplot as plt # Matplotlib for data visualization\n",
    "\n",
    "# Scikit-learn methods\n",
    "from sklearn.cluster import KMeans # K-Means clustering algorithm for partitioning data into clusters\n",
    "from sklearn.mixture import GaussianMixture # Gaussian Mixture Model (GMM) for probabilistic clustering\n",
    "from sklearn.neighbors import kneighbors_graph # Computes the k-nearest neighbor graph\n",
    "from sklearn.metrics import mean_squared_error # Measures the mean squared error for regression tasks\n",
    "\n",
    "# We will use NetworkX objects to store empirical graphs, local datasets, and models.\n",
    "import networkx as nx # NetworkX helps in creating, manipulating, and analyzing graph structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f355472-2414-4de1-bec6-b8b13395c5b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2db6d503a80fe3a104e2e3966b675c04",
     "grade": false,
     "grade_id": "cell-6b141a6410c20685",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f33487-f112-4927-8687-9f5561048103",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84e019b6a8fcfe911730abff98d79fbe",
     "grade": false,
     "grade_id": "cell-9e0fb1a4cd807f69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotFMI(G, save_path=None):\n",
    "    \"\"\"\n",
    "    Generates a scatter plot of FMI stations, coloring nodes based on clusters \n",
    "    and edges with a gradient effect using the nearest node's cluster color.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : networkx.Graph\n",
    "        A graph where each node represents an FMI station, \n",
    "        containing:\n",
    "        - 'coord' (tuple: latitude, longitude) for spatial positioning.\n",
    "        - 'cluster' (int) for cluster assignment.\n",
    "\n",
    "    save_path : str, optional\n",
    "        If provided, saves the plot to the specified file path.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Displays a scatter plot of stations, where:\n",
    "        - Nodes are plotted based on their geographic coordinates.\n",
    "        - Nodes are colored according to their cluster.\n",
    "        - Node labels correspond to their index in the coordinate array.\n",
    "        - Edges are split at the midpoint and colored based on adjacent node clusters.\n",
    "    \"\"\"\n",
    "    # Define colors for clusters\n",
    "    colors = np.array(['black', 'green', 'red', 'brown', 'deeppink',\n",
    "                        'blue', 'olive', 'gray', 'orange', 'purple'])\n",
    "\n",
    "    # Extract coordinates and clusters\n",
    "    coords = np.array([G.nodes[node]['coord'] for node in G.nodes])\n",
    "    clusters = np.array([G.nodes[node]['cluster'] for node in G.nodes])\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Draw nodes, colored by cluster\n",
    "    ax.scatter(coords[:, 1], coords[:, 0], c=colors[clusters], s=50, zorder=5)\n",
    "\n",
    "    # Add labels\n",
    "    for node, (lat, lon) in enumerate(coords):\n",
    "        ax.text(lon + 0.1, lat + 0.2, str(node), fontsize=8, ha='center', va='center', color=colors[clusters[node]], fontweight='bold')\n",
    "\n",
    "    # Draw edges, with half colored by the nearest node's cluster\n",
    "    for u, v in G.edges:\n",
    "        u_color = colors[G.nodes[u]['cluster']]\n",
    "        v_color = colors[G.nodes[v]['cluster']]\n",
    "        u_coords = G.nodes[u]['coord']\n",
    "        v_coords = G.nodes[v]['coord']\n",
    "\n",
    "        # Plot half edges\n",
    "        mid_point = [(u_coords[0] + v_coords[0]) / 2, (u_coords[1] + v_coords[1]) / 2]\n",
    "        ax.plot([u_coords[1], mid_point[1]], [u_coords[0], mid_point[0]], linestyle='-', color=u_color, zorder=3)\n",
    "        ax.plot([mid_point[1], v_coords[1]], [mid_point[0], v_coords[0]], linestyle='-', color=v_color, zorder=3)\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title('FMI Stations Colored by Cluster')\n",
    "    \n",
    "    # Adjust according to Tissot's indicatrix\n",
    "    ax.set_aspect(1.6)\n",
    "    \n",
    "    if save_path != None:\n",
    "        try:\n",
    "            plt.savefig(save_path)\n",
    "        except: \n",
    "            print(\"Failed to save the plot. Invalid file path.\")\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def add_edges(G, z='coord', numneighbors=4):\n",
    "    \"\"\"Adds edges to a graph based on k-nearest neighbors using the representation vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : networkx.Graph\n",
    "        A graph where each node has a 'coord' attribute with (latitude, longitude).\n",
    "    numneighbors : int, optional\n",
    "        Number of nearest neighbors to connect to each node, by default 4.\n",
    "    z : string, optional\n",
    "        The name of the attribute to use as the representation vector, by default 'coord'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    networkx.Graph\n",
    "        A new graph with added edges based on k-nearest neighbors.\n",
    "    \"\"\"\n",
    "    # Deep copy the graph to avoid modifying the original\n",
    "    graph_with_edges = copy.deepcopy(G)\n",
    "\n",
    "    # Extract the representation vector\n",
    "    if z == 'Timestamp':\n",
    "        representation_vector = np.array([graph_with_edges.nodes[node][z].timestamp() for node in graph_with_edges.nodes]).reshape(-1, 1)\n",
    "    else:\n",
    "        representation_vector = np.array([graph_with_edges.nodes[node][z] for node in graph_with_edges.nodes])\n",
    "\n",
    "    # Create adjacency matrix using k-nearest neighbors\n",
    "    adjacency_matrix = kneighbors_graph(representation_vector, \n",
    "                                        numneighbors, \n",
    "                                        mode='connectivity', \n",
    "                                        include_self=False)\n",
    "\n",
    "    # Add edges based on the adjacency matrix\n",
    "    edges = zip(*adjacency_matrix.nonzero())\n",
    "    graph_with_edges.add_edges_from(edges)\n",
    "\n",
    "    return graph_with_edges\n",
    "\n",
    "def ExtractFeatureMatrixLabelVector(data):\n",
    "    \"\"\"Extracts feature matrix and label vector from FMI weather data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame containing columns \"Latitude\", \"Longitude\", \"temp\", \"Timestamp\".\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy.ndarray\n",
    "        Feature matrix where each row corresponds to a data point.\n",
    "    y : numpy.ndarray\n",
    "        Label vector containing temperature values for each data point.\n",
    "    \"\"\"\n",
    "    # Extract temperature values and normalize latitude/longitude.\n",
    "    temps = data['temp'].values\n",
    "    latitudes = data['Latitude'].values / 100\n",
    "    longitudes = data['Longitude'].values / 100\n",
    "\n",
    "    # Extract and normalize time-based features (year, month, day, hour, minute).\n",
    "    timestamps = pd.to_datetime(data['Timestamp'])\n",
    "    year = timestamps.dt.year / 2025\n",
    "    month = timestamps.dt.month / 13\n",
    "    day = timestamps.dt.day / 32\n",
    "    hour = timestamps.dt.hour / 25\n",
    "    minute = timestamps.dt.minute / 61\n",
    "\n",
    "    # Combine features into the feature matrix\n",
    "    X = np.column_stack([latitudes, longitudes, year, month, day, hour, minute])\n",
    "    y = temps.reshape(-1, 1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a8b75-4519-40cc-b6cc-90db6256b517",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09d775443dbe2707d0cbfa702d6806cf",
     "grade": false,
     "grade_id": "cell-105097008e424e25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8965b3a-b3e6-4d41-9bcf-b6a2be099b62",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f53fb2f9bd8b8db231618f5282d3f07",
     "grade": false,
     "grade_id": "cell-bf00ca3974e02a79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the weather measurements\n",
    "data = pd.read_csv('FMI_data.csv')\n",
    "\n",
    "# In this notebook we need an equally-sized local dataset.\n",
    "# This is particularly necessary for vertical FL.\n",
    "# Therefore, we remove all stations with incomplete data.\n",
    "\n",
    "# Identify stations with fewer than 96 entries\n",
    "stations_to_remove = data.groupby('name').filter(lambda x: len(x) < 96)['name'].unique()\n",
    "\n",
    "# Remove rows for these stations\n",
    "data = data[~data['name'].isin(stations_to_remove)]\n",
    "\n",
    "# Convert 'Timestamp' column to datetime\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "\n",
    "# We consider each temperature measurement (=a row in dataframe) as a \n",
    "# separate data point.\n",
    "\n",
    "# Get the number of data points and the number of unique stations.\n",
    "n_stations = len(data.name.unique())\n",
    "n_datapoints = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cacd2-5b21-42d2-975b-d6097d742331",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd3a8275939206064576939b6c06f02e",
     "grade": false,
     "grade_id": "cell-bc936222e13a8dc7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Building an FMI Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb77de-9101-4b04-908b-0e6dfb2d05ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "420cedf19188d2c12bc413a41cfe67fd",
     "grade": false,
     "grade_id": "cell-9e6b78b34c4ba1fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In what follows, we:\n",
    "# 1. construct the empirical graph G_FMI as a networkx.Graph() object,\n",
    "# 2. add a single node for each station,\n",
    "# 3. for each node add the following attributes: \n",
    "#   'samplesize' - The number of measurements of the i-th weather station,\n",
    "#   'name' - the name of the i-th weather station,\n",
    "#   'coord' - the coordinates of the i-th weather station,\n",
    "#   'X', 'y' - the data,\n",
    "#   'cluster' - the cluster to which the node is assigned.\n",
    "\n",
    "# Create a networkX graph\n",
    "G_FMI_no_edges = nx.Graph()\n",
    "\n",
    "# Add one node per station\n",
    "G_FMI_no_edges.add_nodes_from(range(0, n_stations))\n",
    "\n",
    "for i, station in enumerate(data.name.unique()):\n",
    "    # Extract data of the given station\n",
    "    station_data = data[data.name==station]\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X_node, y_node = ExtractFeatureMatrixLabelVector(station_data)\n",
    "    \n",
    "    # Assign node attributes\n",
    "    G_FMI_no_edges.nodes[i].update({\n",
    "        'samplesize': len(y_node), # Number of measurements of the i-th weather station\n",
    "        'name': station, # Name of the i-th weather station\n",
    "        'coord': (station_data.Latitude.iloc[0], station_data.Longitude.iloc[0]), # Coordinates of the i-th weather station\n",
    "        'X': X_node, # Feature matrix for the local dataset at node i\n",
    "        'y': y_node, # Label vector for the local dataset at node i\n",
    "        'cluster': 0 # Cluster assignment (default value = 0)\n",
    "    })\n",
    "\n",
    "# Add edges between each station and its nearest neighbors.\n",
    "# NOTE: The node degree may vary across nodes.\n",
    "G_FMI = add_edges(G_FMI_no_edges, numneighbors=4)\n",
    "print(\"The empirical graph is connected:\", nx.is_connected(G_FMI))\n",
    "\n",
    "# Visualize the empirical graph\n",
    "plotFMI(G_FMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844d9b8-814c-4cf2-b492-4ad863dcb3ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3742c78c6a2109670fd75105c2ad4cbd",
     "grade": false,
     "grade_id": "cell-dfce12eca793b9e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Vertical FL\n",
    "\n",
    "__Problem:__ Each party has different features for the same set of entities or users. For example, different hospitals store different types of medical data for the same group of patients.\n",
    "\n",
    "__Solution:__ Vertical FL uses local datasets that contain the same (identical!) data points. However, each local dataset uses a different choice of features to characterize these data points.   \n",
    "\n",
    "<center>\n",
    "<img src=\"vertical_FL.png\" alt=\"Vertical FL\" width=\"50%\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219d855-7f8c-4288-97c3-c57f03a46a01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "682007ae46b92c400550025d3edb11a4",
     "grade": false,
     "grade_id": "cell-33e2b156fb83c7ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<a id='varying_features'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "### Task 5.1 - Vertical FL\n",
    "\n",
    "__Task description:__\n",
    "1. In contrast to earlier assignments, we now use a global choice for data points: \n",
    "    a data point represents the hourly weather conditions across all of Finland.\n",
    "    The features $\\mathbf{x} = (\\mathcal{x}^{(1)},...,\\mathcal{x^{(n)}})^T$ \n",
    "    of a data point are the local temperature measurements $\\mathcal{x^{(i)}}$ \n",
    "    at FMI stations $\\mathcal{i} = 1,...,\\mathcal{n}$. The label of this data point\n",
    "    is the average temperature (across Finland) during the following hour. Store the features\n",
    "    and labels in `datapoints` (i.e., the $i$-th element of `datapoints` is $(\\mathbf{x}^{(i)}, y^{(i)})$).\n",
    "2. Use the zero-gradient condition (see FLBook, Section 3.4) to compute a solution for the GTVMin instance in matrix form.\n",
    "    \n",
    "__IMPORTANT:__\n",
    "1. Make sure that `datapoints` lists datapoints in the ascending Timestamp order! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f61be-ef5d-4edb-b3ce-d3052035210e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9f95f2666046066b9973150724ac7af",
     "grade": false,
     "grade_id": "cell-fb95844abb558a77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort data by ascending Timestamp\n",
    "data = data.sort_values('Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa2b0c-260a-4d17-ac4b-9c4c048774ea",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6249c0cdaf22d0865b32b27997698023",
     "grade": false,
     "grade_id": "cell-16a2f19b2138cd55",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### TASK ###\n",
    "# datapoints = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb85a180-c0f8-40aa-bb47-3dec6d49bc94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29ff19a6fedb58f1784135e65837e338",
     "grade": false,
     "grade_id": "cell-6607b1c727341c55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Check if the shape of datapoints list is correct\n",
    "assert np.shape(datapoints) == (95, 2), \"The shape of the datapoints list is incorrect.\"\n",
    "assert np.all([np.shape(datapoints[i][0]) == (203,) for i in range(len(datapoints))]), \"Each datapoint should have 203 features.\"\n",
    "\n",
    "print('Sanity check passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ce5f2-67e7-448e-a65b-58d3281d1f44",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00f4ff34b77c80db5ea098a1666660bd",
     "grade": false,
     "grade_id": "cell-cc58ce1ff010377a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all unique Timestamps\n",
    "timestamps = data['Timestamp'].unique()\n",
    "\n",
    "# Create a networkX graph\n",
    "G_FMI_vertical = nx.Graph()\n",
    "\n",
    "# Add one node per hourly measurement\n",
    "G_FMI_vertical.add_nodes_from(range(0, len(datapoints)))\n",
    "\n",
    "for node in G_FMI_vertical.nodes:\n",
    "    # Assign node attributes\n",
    "    G_FMI_vertical.nodes[node].update({\n",
    "        'Timestamp': timestamps[node],\n",
    "        'X': datapoints[node][0], # Feature matrix for the local dataset\n",
    "        'y': datapoints[node][1], # Label vector for the local dataset \n",
    "    })\n",
    "\n",
    "# Add edges\n",
    "G_FMI_vertical = add_edges(G_FMI_vertical, z='Timestamp', numneighbors=4)\n",
    "\n",
    "# Define the regularization parameter\n",
    "gtvmin_alpha = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d70e7-6499-4491-b7a0-6fb6fe2d2b84",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f505e7e9e6a845ae4259813117a23de3",
     "grade": false,
     "grade_id": "cell-6fef0b3fcc0b1df8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### TASK ###\n",
    "# L_FMI = \n",
    "# Q = \n",
    "# q = \n",
    "# hat_w =\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23255e4-a872-40c0-b31e-64ae99be00e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "109d95003028d9e35056d7c8aca37dbe",
     "grade": true,
     "grade_id": "cell-f60eaecccf5727ce",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Check if the shape of datapoints list is correct\n",
    "assert hat_w.shape == (95, 203), \"The shape of the local models' parameters is wrong.\"\n",
    "\n",
    "print('Sanity check passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32251347-09b1-4905-a3fa-e66853fd831c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b72161563ca593928cd8d22a52167b2",
     "grade": false,
     "grade_id": "cell-b9a935d2365f5909",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Clustered FL (CFL)\n",
    "\n",
    "__Problem:__ Single-model FL systems require the local datasets to be well approximated as i.i.d. realizations from a common underlying probability distribution. However, requiring homogeneous local datasets, generated from the same probability distribution, might be overly restrictive. Indeed, the local datasets might be heterogeneous and need to be modelled using different probability distribution [Section 6.3].\n",
    "\n",
    "__Solution:__ CFL assumes that all local datasets in the same cluster have cluster-specific probability distributions. The idea of CFL is to pool the local datasets in the same cluster to obtain a training set for learning cluster-specific model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46da65-1d38-4ac8-ab3e-145ac1466f1a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11965b5c50729fc7877af56e94a5e603",
     "grade": false,
     "grade_id": "cell-ba770c40eafb79ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<a id='varying_features'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "### Task 5.2 - K-Means with different representation vectors\n",
    "__Task description:__ \n",
    "1. Let's define the empirical graph  `G_FMI` as $\\mathcal{G}^{(\\text{FMI})}$.\n",
    "2. Cluster the nodes of $\\mathcal{G}^{(\\text{FMI})}$ using the Python class _[sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)_\n",
    "    which implements the k-means clustering method. This\n",
    "    clustering method requires a representation vector $\\mathbf{z}^{(\\mathcal{i})}$ for each node $\\mathcal{i}$ (FMI\n",
    "    station). You will try out different choices for constructing $\\mathbf{z}^{(\\mathcal{i})}$ of a local\n",
    "    dataset $\\mathcal{D}^{(\\mathcal{i})}$:\n",
    "    * $\\mathbf{z}^{(\\mathcal{i})} \\in \\mathbb{R}^2$ with entries being the latitude and longitude of the FMI \n",
    "    station $\\mathcal{i} \\in \\mathcal{V}$.\n",
    "    *  $\\mathbf{z}^{(\\mathcal{i})}$ is obtained from stacking the parameters of a Gaussian mixture \n",
    "    model (GMM) fitted to the feature vectors $\\mathbf{x}^{(\\mathcal{i},1)},...,\\mathbf{x}^{(\\mathcal{i},m_{\\mathcal{i}})}$.\n",
    "    * $\\mathbf{z}^{(\\mathcal{i})} = (u_{\\mathcal{i}}^{(1)}, u_{\\mathcal{i}}^{(2)}, ..., u_{\\mathcal{i}}^{(k)})^T$ given by the $\\mathcal{i}$-th entries of the eigenvectors\n",
    " $\\mathbf{u}^{(1)}, \\mathbf{u}^{(2)}, ..., \\mathbf{u}^{(k)}$ of the Laplacian matrix $\\mathbf{L}^{(\\text{FMI})}$. Note that $\\mathbf{u}^{(\\mathcal{j})}$ is an\n",
    " eigenvector corresponding to some $\\mathcal{j}$-th smallest eigenvalue $\\lambda_{\\mathcal{j}}$ of $\\mathbf{L}^{(\\text{FMI})}$.\n",
    "4. For each clustering obtained in the previous task, compute the cluster-wise average temperature \n",
    "$$\\hat{\\mathcal{y}}^{(\\mathcal{C})} = \\frac{1}{ \\sum_{\\mathcal{i}' \\in \\mathcal{C}} m_{\\mathcal{i}'} } \\sum_{\\mathcal{i}' \\in \\mathcal{C}} \\sum_{\\mathcal{r}=1}^{m_{\\mathcal{i}'}} \\mathcal{y}^{(\\mathcal{i}',\\mathcal{r})}\n",
    "$$ \n",
    "for each cluster $\\mathcal{C}$. \n",
    "<br>Let $\\mathcal{C^{(i)}}$ denote the cluster to which node $\\mathcal{i}$ belongs, then $\\hat{\\mathcal{y}}^{(\\mathcal{i},\\mathcal{r})} := \\hat{\\mathcal{y}}^{(\\mathcal{C^{(i)}})}$ is a\n",
    "prediction for the actual temperature $\\mathcal{y}^{(\\mathcal{i},\\mathcal{r})}$. Compute the average squared\n",
    "error loss\n",
    "$$\n",
    "\\frac{1}{\\sum_{\\mathcal{i}=1}^{\\mathcal{n}} m_{\\mathcal{i}}}\\sum_{\\mathcal{i \\in V}} \\sum_{\\mathcal{r}=1}^{m_{\\mathcal{i}}}{(\\mathcal{y}^{(\\mathcal{i},\\mathcal{r})} - \\hat{\\mathcal{y}}^{(\\mathcal{i},\\mathcal{r})})^2}\n",
    "$$\n",
    "and store it in the `avg_error` variable.\n",
    "\n",
    "    \n",
    "__Hints:__\n",
    "1. Use `G_FMI` that has been already defined.\n",
    "2. GMM parameters can be extracted with:\n",
    "   * `.means_` - returns the matrix with entries being the mean vectors of each mixture component,\n",
    "   * `.covariances_` - returns the list of covariance matrices of each mixture component,\n",
    "   * `.weights_` - returns the weights of each mixture component.\n",
    "3. Use `.ravel()` to flatten all parameters and `.concatenate()` to stack them together.\n",
    "4. Therefore, the stacked parameters of each node have the shape (114, ). \n",
    "5. The raveled parameters are in the following order: means, covariances, weights. \n",
    "6. After flattening and stacking, the final representation matrix will have dimensions (203, 114), where 203 represents the number of nodes and 114 is the length of each node's representation vector.\n",
    "7. The clustered graph produced by `plotFMI` should visually resemble the following example, though minor variations may occur.\n",
    "\n",
    "<center>\n",
    "<img src=\"clustered_FMI_graph.png\" alt=\"Clustered FMI graph\" width=\"75%\"/>\n",
    "</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a20429-a6ac-4b9b-aa90-13cc392b338e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c812ab03dc597537897acb4656c748b",
     "grade": false,
     "grade_id": "cell-f778dba46a46ff4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the number of clusters and the random seed\n",
    "k = 10\n",
    "seed = 4740 # Use it for KMeans() and GaussianMixture() methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fdbca0-c8b8-4428-9337-8f1d4bc76c21",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7ce5d4db17d9c8ca4b71bb4279d5dc4",
     "grade": false,
     "grade_id": "cell-81a8d5a475e9f487",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### K-Means with coordinates as a representation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a69379-8f40-4dfc-9c63-4a78f4a640ac",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36650a7dadc3c0f761724b460b754812",
     "grade": false,
     "grade_id": "cell-893958ca65241fde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### TASK ###\n",
    "\n",
    "# Average error over all nodes in the graph\n",
    "# avg_error = \n",
    "\n",
    "# Create a list of all coordinates\n",
    "# coordinates = \n",
    "\n",
    "# IMPORTANT: please, set n_init='auto' for KMeans() method to pass the tests!\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "    \n",
    "# Plot the clustered graph\n",
    "plotFMI(G_FMI)\n",
    "\n",
    "# Get the clusters\n",
    "for cluster_i in range(k):\n",
    "    cluster_nodes = [node for node in G_FMI.nodes if G_FMI.nodes[node]['cluster'] == cluster_i]\n",
    "    print(f\"\\033[1mCluster {cluster_i}:\\033[0m\", cluster_nodes)\n",
    "\n",
    "# Print the average error\n",
    "print(f\"\\nThe average squared loss over all data points is {avg_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed9b00-4d5f-43b8-92ff-80066354838b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0bbf1dfc343ac3d47dd67ad92abe758",
     "grade": true,
     "grade_id": "cell-aee5c9993bcc35f7",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Check if the variables store numeric values\n",
    "assert isinstance(avg_error, float), \"The average error must be a numeric value.\"\n",
    "assert avg_error != 0, \"The average error must be equal to zero.\"\n",
    "\n",
    "# Check the shape of the representation matrix\n",
    "assert coordinates.shape == (203, 2), \"The shape of the representation matrix is incorrect.\"\n",
    "\n",
    "# Check the clustering structure\n",
    "x = G_FMI.nodes[27]['cluster'] # Retrieve the cluster ID of node 27\n",
    "cluster_x = [27, 39, 40, 43, 56, 72, 83, 88, 100, 110, 114, 118] # List of nodes that belong to the same cluster as node 27\n",
    "assert np.all([(G_FMI.nodes[node]['cluster'] == x) == (node in cluster_x) for node in G_FMI.nodes]), \"The clustering structure is incorrect.\"\n",
    "\n",
    "print('Sanity check passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4346ee0-d7d2-4b50-842e-9215dcd6dce0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5b69b7ff3134649b0f16564630a3fd3",
     "grade": false,
     "grade_id": "cell-b74591ba3d8cbb6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### K-Means with GMM parameters as a representation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66092ee0-591c-45be-97e8-d3ad31699779",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3589a40f3f9aed8147e94f111cd082a9",
     "grade": false,
     "grade_id": "cell-0bd59f4d7295812b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the number components for the GMM\n",
    "n_components = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c174b1-7250-4011-9651-904ac214250e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfdd7fa7ddba39f2befb0981c59db83f",
     "grade": false,
     "grade_id": "cell-cc33ef99739bdc30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### TASK ###\n",
    "\n",
    "# Average error over all nodes in the graph\n",
    "# avg_error = \n",
    "\n",
    "# Get the GMM parameters of all the nodes in the graph\n",
    "# gmm_params = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "    \n",
    "# Plot the clustered graph\n",
    "plotFMI(G_FMI)\n",
    "\n",
    "# Get the clusters\n",
    "for cluster_i in range(k):\n",
    "    cluster_nodes = [node for node in G_FMI.nodes if G_FMI.nodes[node]['cluster'] == cluster_i]\n",
    "    print(f\"\\033[1mCluster {cluster_i}:\\033[0m\", cluster_nodes)\n",
    "\n",
    "# Print the average error\n",
    "print(f\"\\nThe average squared loss over all datapoints is {avg_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccfb446-d9ee-4301-9518-5e3e46013d10",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df1be0002a00defc753da49a3358b4cf",
     "grade": true,
     "grade_id": "cell-6563c6ea0c50f8bc",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Check if the variables store numeric values\n",
    "assert isinstance(avg_error, float), \"The average error must be a numeric value.\"\n",
    "assert avg_error != 0, \"The average error must be equal to zero.\"\n",
    "\n",
    "# Check the final representation matrix\n",
    "assert gmm_params.shape == (203, 114), \"The shape of representation matrix is incorrect.\"\n",
    "\n",
    "# Check the clustering structure\n",
    "x = G_FMI.nodes[0]['cluster'] # Retrieve the cluster ID of node 0\n",
    "cluster_x = [0, 61] # List of nodes that belong to the same cluster as node 0\n",
    "assert np.all([(G_FMI.nodes[node]['cluster'] == x) == (node in cluster_x) for node in G_FMI.nodes]), \"The clustering structure is incorrect.\"\n",
    "\n",
    "print('Sanity check passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a90013-b1eb-44d7-a6ca-4972fe01ca0e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95de185da1748f6360a069bb1312829d",
     "grade": false,
     "grade_id": "cell-6b2badcf70de723a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### K-Means with eigenvectors of the Laplacian matrix as a representation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38db62e-42e3-4749-a970-f3ab73f6714b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bfa6a6f0167fea4aa96113b740d560c",
     "grade": false,
     "grade_id": "cell-b3178ae4f9d102c2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### TASK ###\n",
    "\n",
    "# Average error over all nodes in the graph\n",
    "# avg_error = \n",
    "\n",
    "# The k smallest eigenvectors to use for clustering\n",
    "# k_eigen = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "    \n",
    "# Plot the clustered graph\n",
    "plotFMI(G_FMI, save_path='clustered_FMI_graph.png')\n",
    "\n",
    "# Get the clusters\n",
    "for cluster_i in range(k):\n",
    "    cluster_nodes = [node for node in G_FMI.nodes if G_FMI.nodes[node]['cluster'] == cluster_i]\n",
    "    print(f\"\\033[1mCluster {cluster_i}:\\033[0m\", cluster_nodes)\n",
    "\n",
    "# Print the average error\n",
    "print(f\"\\nThe average squared loss over all datapoints is {avg_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e1eb4-e1e9-4ede-92e4-e38864d151a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36e313f44be0b74978a75a39ebd12796",
     "grade": true,
     "grade_id": "cell-286ced01a96da397",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Check if the variables store numeric values\n",
    "assert isinstance(avg_error, float), \"The average error must be a numeric value.\"\n",
    "assert avg_error != 0, \"The average error must be equal to zero.\"\n",
    "\n",
    "# Check the final representation matrix\n",
    "assert k_eigen.shape == (203, 10), \"The shape of representation matrix is incorrect.\"\n",
    "\n",
    "# Check the clustering structure\n",
    "x = G_FMI.nodes[0]['cluster'] # Retrieve the cluster ID of node 0\n",
    "cluster_x = [0, 9, 19, 28, 39, 58, 61, 66, 75, 83, 112, 115, 173, 188] # List of nodes that belong to the same cluster as node 0\n",
    "assert np.all([(G_FMI.nodes[node]['cluster'] == x) == (node in cluster_x) for node in G_FMI.nodes]), \"The clustering structure is incorrect.\"\n",
    "\n",
    "print('Sanity check passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d417e-a0bb-4c3e-93ce-f9d5461900fd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62e854c9233afff89f57e17df60ee590",
     "grade": false,
     "grade_id": "cell-1c71a8fb2eb7cdfe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<a id='varying_features'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "### Question 5.1 - Single-Model FL\n",
    "\n",
    "__Formulation:__\n",
    "\n",
    "For which scenarios is clustered FL preferable over single-model FL?\n",
    "    \n",
    "__Answer Options:__\n",
    "    \n",
    "1. The local datasets are heterogeneous in the sense of having different statistical properties. \n",
    "2. The local datasets have similar statistical properties, but some of them are too small.\n",
    "3. The local datasets have similar statistical properties, but some of them are too large.\n",
    "4. The local datasets have similar statistical properties, but some local datasets use different features for datapoints.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886becb4-f939-42ad-90ac-30bfcd44235f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "652ce4e22dbee2bc7b28da06b8674e9c",
     "grade": false,
     "grade_id": "cell-30cdb354dabf46c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Question ###\n",
    "\n",
    "# Assign the variable to the answer option from the list above\n",
    "# answer =\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691b784-4103-45fc-bfbe-09ce1a5f339c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ad6a9edb153f43bae02458839a1fc54",
     "grade": true,
     "grade_id": "cell-c8648c2322d569fa",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Check if the chosen answer option is adequate\n",
    "assert answer in [1, 2, 3, 4], \"Choose the answer option from the provided list.\"\n",
    "\n",
    "print('Sanity check passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5fad9-b5c5-4206-b953-36b8554e98f4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "581e84a33cbd75d8cd9f9054d998c3c0",
     "grade": false,
     "grade_id": "cell-0fb916728588e309",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<a id='varying_features'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "### Question 5.2 - Horizontal FL\n",
    "\n",
    "__Formulation:__\n",
    "\n",
    "Which of the following statements characterize horizontal FL?    \n",
    "    \n",
    "__Answer Options:__\n",
    "    \n",
    "1. The data points must be characterized by the same features in all local datasets.\n",
    "2. Horizontal FL can be considered a form of semi-supervised learning.\n",
    "3. All local datasets must contain identical data points.\n",
    "4. The features used in a local dataset must be a proper subset of the raw features measured for each data point.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6c56e-30ea-43f4-b386-a30bca5121ae",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe697593f2d58d28f3506e5a102ea18e",
     "grade": false,
     "grade_id": "cell-0cb3300d51592e8a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Question ###\n",
    "\n",
    "# Assign the variable to the set containing correct answers\n",
    "# answer =\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02dcd89-8017-4636-a293-af72654eea7c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "802507d4615229d5c17282bc0b515e6d",
     "grade": true,
     "grade_id": "cell-08c2ecf67f068239",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Check if the variable is a set\n",
    "assert isinstance(answer, set), \"The answer is not a set.\"\n",
    "\n",
    "# Check if the chosen answer option is adequate\n",
    "assert answer.issubset({1, 2, 3, 4}), \"Choose the answer options from the provided list.\"\n",
    "\n",
    "print('Sanity check passed!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
